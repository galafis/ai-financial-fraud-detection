# ğŸ§ª Tests - Sistema de DetecÃ§Ã£o de Fraudes Financeiras

DocumentaÃ§Ã£o completa da suÃ­te de testes automatizados do projeto AI Financial Fraud Detection, incluindo organizaÃ§Ã£o, execuÃ§Ã£o, boas prÃ¡ticas e critÃ©rios de qualidade.

## ğŸ“ Estrutura de OrganizaÃ§Ã£o

```
tests/
â”œâ”€â”€ unit/                    # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ README.md           # DocumentaÃ§Ã£o especÃ­fica dos testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_models/        # Testes dos modelos de ML
â”‚   â”œâ”€â”€ test_features/      # Testes de feature engineering
â”‚   â”œâ”€â”€ test_data/          # Testes de processamento de dados
â”‚   â””â”€â”€ test_utils/         # Testes de utilitÃ¡rios
â”œâ”€â”€ integration/            # Testes de integraÃ§Ã£o
â”‚   â”œâ”€â”€ README.md           # DocumentaÃ§Ã£o especÃ­fica dos testes de integraÃ§Ã£o
â”‚   â”œâ”€â”€ test_api/           # Testes da API REST
â”‚   â”œâ”€â”€ test_pipeline/      # Testes do pipeline completo
â”‚   â””â”€â”€ test_streaming/     # Testes de processamento em tempo real
â”œâ”€â”€ performance/            # Testes de performance
â”‚   â”œâ”€â”€ README.md           # DocumentaÃ§Ã£o especÃ­fica dos testes de performance
â”‚   â”œâ”€â”€ test_latency/       # Testes de latÃªncia
â”‚   â”œâ”€â”€ test_throughput/    # Testes de throughput
â”‚   â””â”€â”€ test_load/          # Testes de carga
â”œâ”€â”€ fixtures/               # Dados de teste e fixtures
â”‚   â”œâ”€â”€ sample_data/        # Dados de exemplo para testes
â”‚   â””â”€â”€ mocks/              # Mocks e stubs
â”œâ”€â”€ conftest.py             # ConfiguraÃ§Ãµes pytest compartilhadas
â””â”€â”€ README.md               # Esta documentaÃ§Ã£o
```

## ğŸ¯ Tipos de Testes

### 1. Testes UnitÃ¡rios (`unit/`)
- **Objetivo**: Testar componentes individuais isoladamente
- **Escopo**: FunÃ§Ãµes, classes e mÃ©todos especÃ­ficos
- **Cobertura**: â‰¥90% para mÃ³dulos crÃ­ticos, â‰¥80% geral
- **ExecuÃ§Ã£o**: RÃ¡pida (<1s por teste)

### 2. Testes de IntegraÃ§Ã£o (`integration/`)
- **Objetivo**: Testar interaÃ§Ã£o entre componentes
- **Escopo**: APIs, pipelines de dados, conexÃµes externas
- **Cobertura**: Todos os endpoints e fluxos principais
- **ExecuÃ§Ã£o**: Moderada (1-10s por teste)

### 3. Testes de Performance (`performance/`)
- **Objetivo**: Validar requisitos nÃ£o-funcionais
- **Escopo**: LatÃªncia, throughput, uso de memÃ³ria
- **MÃ©tricas**: <100ms latÃªncia, >1000 transaÃ§Ãµes/s
- **ExecuÃ§Ã£o**: Lenta (10s-5min por teste)

## ğŸš€ ExecuÃ§Ã£o dos Testes

### Comandos BÃ¡sicos

```bash
# Instalar dependÃªncias de teste
pip install -r requirements-test.txt

# Executar todos os testes
pytest

# Executar testes especÃ­ficos por categoria
pytest tests/unit/                    # Somente unitÃ¡rios
pytest tests/integration/            # Somente integraÃ§Ã£o
pytest tests/performance/            # Somente performance

# Executar testes com cobertura
pytest --cov=src --cov-report=html --cov-report=term

# Executar testes em paralelo
pytest -n auto

# Executar testes especÃ­ficos
pytest tests/unit/test_models/test_fraud_detector.py
pytest -k "test_fraud_detection"     # Por nome
pytest -m "slow"                     # Por marcador
```

### ConfiguraÃ§Ãµes de ExecuÃ§Ã£o

```bash
# ExecuÃ§Ã£o verbosa com detalhes
pytest -v --tb=short

# ExecuÃ§Ã£o com relatÃ³rio JUnit (CI/CD)
pytest --junitxml=reports/junit.xml

# ExecuÃ§Ã£o com falhas primeiro (fail-fast)
pytest -x

# ExecuÃ§Ã£o com re-execuÃ§Ã£o de falhas
pytest --lf  # last-failed
pytest --ff  # failed-first
```

## ğŸ“Š CritÃ©rios de Cobertura

### Metas de Cobertura por MÃ³dulo

| MÃ³dulo | Cobertura MÃ­nima | Cobertura Meta |
|--------|------------------|----------------|
| `src/models/` | 90% | 95% |
| `src/features/` | 85% | 90% |
| `src/inference/` | 90% | 95% |
| `src/api/` | 80% | 85% |
| `src/data/` | 75% | 80% |
| `src/utils/` | 70% | 75% |

### MÃ©tricas de Qualidade

```bash
# RelatÃ³rio completo de cobertura
pytest --cov=src --cov-report=html

# Verificar cobertura com falha se abaixo do limite
pytest --cov=src --cov-fail-under=80

# Excluir arquivos de configuraÃ§Ã£o da cobertura
pytest --cov=src --cov-report=term --cov-config=.coveragerc
```

## ğŸ—ï¸ Boas PrÃ¡ticas para Desenvolvimento

### 1. Nomenclatura de Testes

```python
# âŒ Evitar
def test1():
def test_function():

# âœ… Recomendado
def test_fraud_detector_returns_high_score_for_suspicious_transaction():
def test_feature_engineering_handles_missing_values_correctly():
def test_api_returns_400_when_invalid_transaction_data():
```

### 2. Estrutura de Testes (AAA Pattern)

```python
def test_fraud_detection_model_prediction():
    # Arrange - Preparar dados e dependÃªncias
    model = FraudDetectionModel()
    transaction = {
        "amount": 1500.0,
        "merchant": "Online Store",
        "location": "SÃ£o Paulo"
    }
    
    # Act - Executar aÃ§Ã£o a ser testada
    prediction = model.predict(transaction)
    
    # Assert - Verificar resultados
    assert prediction["fraud_probability"] > 0.5
    assert "risk_factors" in prediction
```

### 3. Uso de Fixtures

```python
# conftest.py
@pytest.fixture
def sample_transaction():
    return {
        "amount": 100.0,
        "merchant": "Test Store",
        "timestamp": "2024-01-15T10:00:00"
    }

@pytest.fixture
def trained_model():
    model = FraudDetectionModel()
    model.load_model("models/test_model.pkl")
    return model
```

### 4. Marcadores de Teste

```python
import pytest

@pytest.mark.unit
def test_feature_extraction():
    pass

@pytest.mark.integration
def test_api_endpoint():
    pass

@pytest.mark.slow
def test_model_training():
    pass

@pytest.mark.parametrize("amount,expected", [
    (100.0, "low_risk"),
    (5000.0, "high_risk"),
])
def test_risk_classification(amount, expected):
    pass
```

## ğŸ”§ ConfiguraÃ§Ã£o do Ambiente de Testes

### 1. Arquivo pytest.ini

```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_functions = test_*
python_classes = Test*
markers =
    unit: Testes unitÃ¡rios rÃ¡pidos
    integration: Testes de integraÃ§Ã£o
    performance: Testes de performance
    slow: Testes que demoram mais de 10s
addopts = 
    --strict-markers
    --strict-config
    --verbose
```

### 2. VariÃ¡veis de Ambiente

```bash
# .env.test
DATABASE_URL=sqlite:///test.db
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
REDIS_URL=redis://localhost:6379/1
LOG_LEVEL=DEBUG
```

### 3. DependÃªncias de Teste

```bash
# requirements-test.txt
pytest==7.4.0
pytest-cov==4.1.0
pytest-xdist==3.3.1
pytest-mock==3.11.1
pytest-asyncio==0.21.1
pytest-benchmark==4.0.0
factory-boy==3.3.0
faker==19.3.0
responses==0.23.3
```

## ğŸ“ˆ EstratÃ©gia de ExpansÃ£o dos Testes

### 1. AdiÃ§Ã£o de Novos Testes

1. **Identificar Funcionalidade**: Nova feature ou correÃ§Ã£o de bug
2. **Classificar Tipo**: Unit, Integration ou Performance
3. **Definir CenÃ¡rios**: Happy path, edge cases, error cases
4. **Implementar Testes**: Seguindo padrÃµes estabelecidos
5. **Validar Cobertura**: Verificar se atende critÃ©rios

### 2. ManutenÃ§Ã£o ContÃ­nua

```bash
# Script de verificaÃ§Ã£o da qualidade dos testes
./scripts/test-quality-check.sh

# Linting de cÃ³digo de teste
flake8 tests/
black tests/
isort tests/

# VerificaÃ§Ã£o de testes obsoletos
pytest --collect-only | grep -i "deprecated"
```

### 3. AutomaÃ§Ã£o CI/CD

```yaml
# .github/workflows/tests.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Tests
        run: |
          pytest --cov=src --cov-report=xml
          pytest tests/integration/ --maxfail=1
          pytest tests/performance/ --benchmark-json=benchmark.json
```

## ğŸ“š DocumentaÃ§Ã£o EspecÃ­fica

Consulte os READMEs especÃ­ficos de cada categoria para detalhes tÃ©cnicos:

- [`unit/README.md`](unit/README.md) - Testes unitÃ¡rios especÃ­ficos
- [`integration/README.md`](integration/README.md) - Testes de integraÃ§Ã£o e API
- [`performance/README.md`](performance/README.md) - Benchmarks e testes de carga

## ğŸ› ï¸ Ferramentas Auxiliares

### Debugging de Testes

```bash
# Executar com debugger
pytest --pdb

# Executar com profiling
pytest --profile

# Capturar prints durante execuÃ§Ã£o
pytest -s
```

### RelatÃ³rios e MÃ©tricas

```bash
# RelatÃ³rio HTML interativo
pytest --cov=src --cov-report=html
open htmlcov/index.html

# Benchmark comparativo
pytest --benchmark-compare=0001_baseline.json
```

## ğŸš¨ Troubleshooting Comum

### Problemas Frequentes

1. **Testes Lentos**: Use `-n auto` para paralelizaÃ§Ã£o
2. **Fixtures NÃ£o Encontradas**: Verificar `conftest.py`
3. **Import Errors**: Configurar `PYTHONPATH` corretamente
4. **Database Locks**: Usar transaÃ§Ãµes isoladas para testes

### Contato e Suporte

Para dÃºvidas sobre testes ou contribuiÃ§Ãµes:
- Abrir issue no repositÃ³rio
- Consultar documentaÃ§Ã£o em `docs/testing-guide.md`
- Revisar exemplos em cada subdiretÃ³rio

---

**Nota**: Esta documentaÃ§Ã£o deve ser atualizada sempre que novos padrÃµes ou ferramentas de teste forem adotados no projeto.
